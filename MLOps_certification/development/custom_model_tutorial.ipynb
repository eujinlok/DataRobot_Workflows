{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building, Testing, and Deploying a Custom Model\n",
    "\n",
    "This notebook walks through the general workflow for building, testing, and deploying a custom inference model on a custom environment. \n",
    "\n",
    "## Agenda\n",
    "In this tutorial, we'll learn:\n",
    "<br/>\n",
    "1. How to use the client to create an environment<br/>\n",
    "2. How to check the status of an environment build<br/>\n",
    "3. How to create a custom model<br/>\n",
    "4. How to iteratively test and debug a custom model on a custom environment<br/>\n",
    "5. How to deploy and run predictions on a tested custom model.<br/>\n",
    "\n",
    "## Setup and Requirements\n",
    "This tutorial assumes a few things about your filepath and prior work. \n",
    "\n",
    "**Firstly, you need two different feature flags enabled:**\n",
    "1. Enable Custom Inference Models\n",
    "2. Enable Experimental API Access\n",
    "\n",
    "Secondly, you should have a folder at the path `~/custom-model-templates/`. If you put the folder in a different location, make sure you update the `TESTING_PATH` variable. This folder should contain 4 things:\n",
    "<br/>\n",
    "\n",
    "1. A folder containing your properly configured custom environment.     \n",
    "    In this example, it's named `custom_environment_templates/python_3/py3_sklearn_base/`\n",
    "    \n",
    "    \n",
    "2. A folder containing your properly-configured custom model.     \n",
    "    In this example, it's named `custom_model_templates/python_model/`\n",
    "    \n",
    "    \n",
    "3. The current version of the custom model API client, found at the following link: [API client](https://github.com/datarobot/py-dse). \n",
    "    - The client can also be installed via pip using DataRobot's artifactory. [DR Artifactory tutorial](https://datarobot.atlassian.net/wiki/spaces/DEVINFRA/pages/620265476/Artifactory+User+Guide).\n",
    "    - Full documentation for the client can be found here: [DSE API Client Docs](http://py-dse.docs.hq.datarobot.com/index.html)\n",
    "\n",
    "\n",
    "4. A test dataset that you can use to test predictions from your custom model.     \n",
    "    In this example, it's stored at `custom_model_templates/python_model/extras/training_data/10k_diabetes_no_null_text.csv`\n",
    "\n",
    "It also assumes that you have access to staging.datarobot.com, which means that **you must have your vpn on**.\n",
    "\n",
    "## Configuring Models and Environments\n",
    "For more information on how to properly configure custom models and environments, read the README of our [custom model templates repository](https://github.com/datarobot/custom-model-templates).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "First we setup a python environment to contain the correct libraries and versions. Follow these steps:\n",
    "\n",
    "- Go to the location: \n",
    "```\n",
    "cd ~/Documents/GIT-Projects/data-science-scripts/eujinlok/MLOps-Demo-Certification\n",
    "```\n",
    "- Initialise environment: \n",
    "```\n",
    "python3 -m venv myenv\n",
    "```\n",
    "- Activate environment:\n",
    "```\n",
    "source myenv/bin/activate\n",
    "```\n",
    "\n",
    "- Run jupyter notebook by typing on the terminal:\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/eu.jin.lok/Documents/GIT-Projects/DataRobot_Workflows/MLOps_certification/development'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First, we need to make the proper imports. Make sure the `TESTING_PATH` is correct and pointing to the right folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Install these libraries via: pip install -r requirements.txt\n",
    "# Highly recommend to install this before installing the datarobot-DSE client\n",
    "# Also install any datarobot-DSE dependencies outside of Artifactory or it will take hours to install\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import logging\n",
    "from io import open\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where you save the `TESTING_PATH` that contains the relevant folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the path to the custom model testing folder, and add it to the PYTHONPATH so we can import the client\n",
    "# NOTE: Installing datarobot DSE client needs to go via Artifactory and thus activating the VPN. \n",
    "# Remember to switch on/off the Artificatory pip install path on the .pip folder\n",
    "TESTING_PATH = os.getcwd() + '/'\n",
    "sys.path.append(TESTING_PATH)\n",
    "\n",
    "from datarobot.dse import DSEClient \n",
    "from datarobot.dse.enums import CustomModelType, DeploymentType, DatasetCategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Configuring User Credentials\n",
    "Make sure to fill in your username and API token from staging.datarobot.com. \n",
    "\n",
    "Also ensure that all the paths are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save user credentials ##\n",
    "with open('/Users/eu.jin.lok/Documents/GIT-Projects/creds.json') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "TOKEN = param['token']\n",
    "USERNAME = param['username']\n",
    "\n",
    "## Save path to environment ##\n",
    "environment_folder = TESTING_PATH + 'Custom-Environment/python_3/py3_sklearn_base/'\n",
    "\n",
    "## Save path to custom model ##\n",
    "custom_model_folder = TESTING_PATH + 'Custom-Model/python_model/'\n",
    "\n",
    "## Save test dataset path ##\n",
    "test_dataset = TESTING_PATH + 'Custom-Model/python_model/extras/training_data/10k_diabetes_no_null_text.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the API clients\n",
    "This saves the staging API clients for custom models testing and predictions. **You shouldn't need to change anything in this block if you configured your credentials properly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure client\n",
    "client = DSEClient(\n",
    "    base_url='https://app.datarobot.com/api/v2',\n",
    "    username=USERNAME,\n",
    "    token=TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Environment\n",
    "This command creates a custom environment! When you run the command, it uploads your Docker context and we attempt to build the Docker Image (the container that your model will eventually run in). \n",
    " \n",
    "Depending on the environment and the libraries you want to download, this process can take a while (10-30 minutes)! This command sets the wait time to 30 minutes, but if it fails with a RunTimeError, it's possible that the environment is still processing and could still succeed.\n",
    "\n",
    "### Custom Environment Templates\n",
    "We have a repository for custom environment templates here: [environment templates](https://github.com/datarobot/custom-model-templates/tree/master/custom_environment_templates)\n",
    "\n",
    "You'll find templates for Python 2 and Python 3 environments. Over time, we will continue to add more templates to this repository for more languages: R, Scala, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the environment, which will eventually contain versions  ##\n",
    "execution_environment = client.execution_environments.create(\n",
    "    name=\"Python3 Sklearn Environment\",\n",
    "    description=\"This environment contains a set of Python3 libraries, including pandas, sklearn, and keras.\",\n",
    ")\n",
    "\n",
    "## Create the environment version ##\n",
    "environment_version = execution_environment.versions.sync_create(\n",
    "    environment_path=environment_folder,\n",
    "    timeout=3600,  # 1 hour timeout\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Model\n",
    "Once the Custom Environment is successfully built, now it's time to build the Custom Model. You will need to define details about your custom model in this command, depending on the type of model.\n",
    "\n",
    "### Required fields:\n",
    "`model_path` : string containing the path to the model folder\n",
    "\n",
    "`name` : string that defines the name of the model\n",
    "\n",
    "`target_name` : string that defines the name of the target column that the model was trained on\n",
    "\n",
    "`supports_binary_classification` : boolean that describes the target type. True if the model is trained for Binary Classification\n",
    "\n",
    "`supports_regression` : boolean that describes the target type. True if the model is trained for Regression. \n",
    "Only one of these labels should be set to True.\n",
    "\n",
    "`positive_class_label` : string that defines the \"positive class\". Only required for Binary Classification models\n",
    "\n",
    "`negative_class_label` : string that defines the \"negative class\". Only required for Binary Classification models\n",
    "\n",
    "### Optional Fields:\n",
    "`prediction_threshold` : a float that defines the prediction threshold for binary classification. This value is used for features and charts in MMM.\n",
    "\n",
    "`description` : a string that describe the model. User can input whatever they want for the description.\n",
    "\n",
    "`language` : a string that details the language the model uses. User can input whatever they want for the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the custom model ##\n",
    "custom_model = client.custom_models.create(\n",
    "    model_path=custom_model_folder,\n",
    "    custom_model_type=CustomModelType.INFERENCE,\n",
    "    name='Python 3 Sklearn Custom Model',\n",
    "    supports_binary_classification=True,\n",
    "    prediction_threshold=0.5,\n",
    "    target_name='readmitted',\n",
    "    positive_class_label='Yes',\n",
    "    negative_class_label='No',\n",
    "    description='This is a Python3-based custom model. It has a simple sklearn Pipeline built on 10k diabetes',\n",
    "    language='Python 3'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Testing Workflow\n",
    "Just because you created an environment and a model doesn't mean that it will actually work in production! There are all sorts of things that can go wrong, whether on the engineering side or the data science side. Bad code, an environment with the wrong versions of libraries, or even a model that can't handle missing values in the inference data can all lead to a model that will break in production.\n",
    "\n",
    "With this in mind, we created an easy way to ensure that a custom inference model will work in production: You can actually test your model with a specific environment using sample inference data before deploying the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing Step 1: Save ids\n",
    "To facilitate quicker and easier testing, save the environment and model ids and version ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you've saved the environment and model version\n",
    "model_version = custom_model.latest_version\n",
    "\n",
    "print(model_version)\n",
    "# CustomModelVersion(description='', created='2019-11-25T22:31:40.673776Z', file_name='model.tgz', meta={}, label='v1', id='245d4e2a2408858625024fb3248a2a372245cf3a')\n",
    "\n",
    "print(\"\\n\")\n",
    "print(environment_version)\n",
    "# ExecutionEnvironmentVersion(environment_id='5ddc55ee7fe7aa3d43b6cc0e', description='', created='2019-11-25T22:30:07.033503Z', label='Version 1', id='5ddc55efe6858f065c10534c', build_status='success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run the Test\n",
    "To run a custom model test, you upload and save a test dataset from the sample inference data. Then, you simply select the appropriate model and environment (as well as version) IDs, and test it on that dataset.\n",
    "\n",
    "Depending on the k8s cluster and the model itself, it may take a few minutes to test the model. Once the test is finished, it will have a status property to let you know whether the test passed. If it failed, it will contain an `error` property that contains the relevant error!\n",
    "\n",
    "An important note: As of right now, the only available test is an error check, where we simply ensure the model can return predictions. In the future, we will add more tests to that suite: prediction consistency, missing value handling, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.datasets.sync_create(\n",
    "    dataset_path=test_dataset,\n",
    "    categories=DatasetCategory.CUSTOM_MODEL_TESTING,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform custom model test\n",
    "custom_model_test = client.custom_model_tests.sync_create(\n",
    "    timeout=3600,  # 1 hour timeout\n",
    "    custom_model_id=custom_model.id, \n",
    "    custom_model_version_id=model_version.id,\n",
    "    environment_id=execution_environment.id, \n",
    "    environment_version_id=environment_version.id,\n",
    "    dataset_id=dataset.dataset_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test statuses: {}\".format(custom_model_test.testing_status))\n",
    "# Test statuses: {'errorCheck': {'status': 'succeeded', 'message': ''}, 'sideEffects': {'status': 'not_tested', 'message': ''}, 'longRunningService': {'status': 'succeeded', 'message': ''}}\n",
    "\n",
    "if any(test['status'] == 'failed' for test in custom_model_test.testing_status.values()):\n",
    "    print('Test log:\\n')\n",
    "    print(custom_model_test.log)\n",
    "else:\n",
    "    print('Testing succeeded!')\n",
    "# Testing succeeded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Iterate\n",
    "If the test passed, then congratulations! You can skip this test; your model is ready to be deployed. If it failed the test however, it's easy to iterate. \n",
    "\n",
    "First, check the error from the custom model test. Then, fix any errors in the code that you uploaded. Finally, upload a new version of the model using the updated code, and test it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new version of custom model. Repeat these last two blocks until the model passes testing!\n",
    "model_version = custom_model.versions.create(model_path=custom_model_folder,\n",
    "                                             description='Fixing errors from testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform custom model test... again\n",
    "custom_model_test = client.custom_model_tests.sync_create(\n",
    "    timeout=3600,  # 1 hour timeout\n",
    "    custom_model_id=custom_model.id, \n",
    "    custom_model_version_id=model_version.id,\n",
    "    environment_id=execution_environment.id, \n",
    "    environment_version_id=environment_version.id,\n",
    "    dataset_id=dataset.dataset_id,\n",
    ")\n",
    "\n",
    "print(\"Test statuses: {}\".format(custom_model_test.testing_status))\n",
    "\n",
    "if any(test['status'] == 'failed' for test in custom_model_test.testing_status.values()):\n",
    "    print('Test log:\\n')\n",
    "    print(custom_model_test.log)\n",
    "\n",
    "else:\n",
    "    print('Testing succeeded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command shows all tests that have been run on the model\n",
    "model_tests = client.custom_model_tests.list(custom_model_id=custom_model.id)\n",
    "print(model_tests)\n",
    "# RESTList(objects=[CustomModelTest(custom_model_image_id='5ddc57207fe7aa3d70b6cc06', custom_model={'id': '5ddc564c3bcc11065acc148c', 'name': 'Python 3 Sklearn Custom Model'}, execution_environment={'id': '5ddc55ee7fe7aa3d43b6cc0e', 'name': 'Python3 Sklearn Environment'}, testing_status={'errorCheck': {'status': 'succeeded', 'message': ''}, 'longRunningService': {'status': 'succeeded', 'message': ''}, 'sideEffects': {'status': 'not_tested', 'message': ''}}, created='2019-11-25T22:35:12.771178Z', custom_model_version={'id': '245d4e2a2408858625024fb3248a2a372245cf3a', 'label': 'v1'}, dataset_version_id='5ddc56dde6858f057010547d', execution_environment_version={'id': '5ddc55efe6858f065c10534c', 'label': 'Version 1'}, created_by='eu.jin.lok@datarobot.com', completed_at='2019-11-25T22:36:14.659379Z', id='5ddc57207fe7aa3d70b6cc12', dataset_id='5ddc56dce6858f057010547c')], next_page_link=None, previous_page_link=None, count=1, total=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model\n",
    "To deploy an inference model, you create something called a `custom_model_image`, which saves the custom model code with a _specific_ environment. This will make it easy to see which custom models have been tested or deployed on specific environments.\n",
    "\n",
    "Once you have the desired custom model image, simply call the `client.deployments.sync_create()` method, inputting the model image's id, the prediction server's `instance_id`, the inference model deployment type, and the desired deployment label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the client is using the correct prediction server to deploy the model. \n",
    "# This uses the prediction server for testing on staging.\n",
    "\n",
    "available_prediction_server_urls = [\n",
    "    \"https://cfds-ccm-prod.orm.datarobot.com\",\n",
    "]\n",
    "\n",
    "for prediction_server in client.prediction_servers:\n",
    "    if prediction_server.url in available_prediction_server_urls:\n",
    "        instance_id = prediction_server.id\n",
    "        break\n",
    "else:\n",
    "    raise Exception(\"no suitable prediction server found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_image = client.custom_model_images.create(\n",
    "    custom_model_id=custom_model.id,\n",
    "    custom_model_version_id=model_version.id,\n",
    "    environment_id=execution_environment.id,\n",
    "    environment_version_id=environment_version.id,\n",
    ")\n",
    "\n",
    "\n",
    "deployment = client.deployments.sync_create(\n",
    "    timeout=3600,  # 1 hour timeout\n",
    "    model_id=custom_model_image.id,\n",
    "    # instance id is only required for Cloud DataRobot App\n",
    "    # ignore for on-premises Platform installations.\n",
    "    instance_id=instance_id,\n",
    "    deployment_type=DeploymentType.CUSTOM_INFERENCE_MODEL,\n",
    "    label='Test client deployment',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on a deployed custom inference model\n",
    "Predictions look exactly the same for a custom inference model and a native DR model. If training data was assigned to the model, then we can also provide predictions explanations and all MMM features, deeply integrated with the custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the custom model deployment\n",
    "predictions = deployment.predict(test_dataset)\n",
    "pprint(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
